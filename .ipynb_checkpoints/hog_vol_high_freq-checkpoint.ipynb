{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incident-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from cme_calendar import CMEHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stylish-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of our custom CME calendar to use to drop holidays and such\n",
    "cme_cal = CustomBusinessDay(calendar=CMEHolidayCalendar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "integral-pharmacology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samgruenler/opt/anaconda3/envs/utc/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUL18\n",
      "JUN18\n",
      "APR18\n",
      "DEC18\n",
      "AUG18\n",
      "MAY18\n",
      "OCT18\n",
      "FEB18\n",
      "FEB19\n",
      "APR19\n",
      "MAY19\n",
      "JUN19\n",
      "JUL19\n",
      "AUG19\n",
      "FEB21\n",
      "APR21\n",
      "MAY21\n",
      "JUN21\n",
      "JUL21\n",
      "AUG21\n",
      "OCT21\n",
      "DEC21\n",
      "FEB22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Index</th>\n",
       "      <th>Product</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Price</th>\n",
       "      <th>???</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-05 08:30:00-06:00</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>40830.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>83.700</td>\n",
       "      <td>\\N</td>\n",
       "      <td>08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05 08:31:00-06:00</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>41251.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>83.650</td>\n",
       "      <td>\\N</td>\n",
       "      <td>08:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05 08:32:00-06:00</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>41562.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>83.800</td>\n",
       "      <td>\\N</td>\n",
       "      <td>08:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05 08:33:00-06:00</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>41767.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>83.750</td>\n",
       "      <td>\\N</td>\n",
       "      <td>08:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05 08:34:00-06:00</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>42065.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>83.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>08:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 11:56:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163314.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 11:57:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163314.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 11:58:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163314.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 11:59:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163452.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 12:00:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163498.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.750</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30847 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Day      Index Product Contract   Price ???  \\\n",
       "Central_Time                                                                   \n",
       "2018-02-05 08:30:00-06:00 2018-02-05    40830.0      HE    JUL18  83.700  \\N   \n",
       "2018-02-05 08:31:00-06:00 2018-02-05    41251.0      HE    JUL18  83.650  \\N   \n",
       "2018-02-05 08:32:00-06:00 2018-02-05    41562.0      HE    JUL18  83.800  \\N   \n",
       "2018-02-05 08:33:00-06:00 2018-02-05    41767.0      HE    JUL18  83.750  \\N   \n",
       "2018-02-05 08:34:00-06:00 2018-02-05    42065.0      HE    JUL18  83.725  \\N   \n",
       "...                              ...        ...     ...      ...     ...  ..   \n",
       "2018-07-16 11:56:00-05:00 2018-07-16  4163314.0      HE    JUL18  79.725  \\N   \n",
       "2018-07-16 11:57:00-05:00 2018-07-16  4163314.0      HE    JUL18  79.725  \\N   \n",
       "2018-07-16 11:58:00-05:00 2018-07-16  4163314.0      HE    JUL18  79.725  \\N   \n",
       "2018-07-16 11:59:00-05:00 2018-07-16  4163452.0      HE    JUL18  79.725  \\N   \n",
       "2018-07-16 12:00:00-05:00 2018-07-16  4163498.0      HE    JUL18  79.750  \\N   \n",
       "\n",
       "                               Time  \n",
       "Central_Time                         \n",
       "2018-02-05 08:30:00-06:00  08:30:00  \n",
       "2018-02-05 08:31:00-06:00  08:31:00  \n",
       "2018-02-05 08:32:00-06:00  08:32:00  \n",
       "2018-02-05 08:33:00-06:00  08:33:00  \n",
       "2018-02-05 08:34:00-06:00  08:34:00  \n",
       "...                             ...  \n",
       "2018-07-16 11:56:00-05:00  11:56:00  \n",
       "2018-07-16 11:57:00-05:00  11:57:00  \n",
       "2018-07-16 11:58:00-05:00  11:58:00  \n",
       "2018-07-16 11:59:00-05:00  11:59:00  \n",
       "2018-07-16 12:00:00-05:00  12:00:00  \n",
       "\n",
       "[30847 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_vol_df = pd.read_csv(\"../data/he_futures_data.csv\", names=[\"Index\", \"Product\", \"Contract\", \n",
    "                                                                  \"Price\", \"Date\", \"???\"])\n",
    "\n",
    "# slice by contract right off the bat\n",
    "exp_months = hog_vol_df[\"Contract\"].unique()\n",
    "\n",
    "contract_vol_dict = {}\n",
    "\n",
    "for month in exp_months:\n",
    "    mon_df = hog_vol_df.loc[hog_vol_df[\"Contract\"] == month]\n",
    "    mon_df.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    mon_df.index = pd.to_datetime(mon_df.index)\n",
    "    \n",
    "    ###### want to get rid of all of the data that isn't by seconds\n",
    "    mon_df[\"Day\"] = mon_df.index.date\n",
    "    mon_df = mon_df.loc[(mon_df[\"Day\"] == mon_df[\"Day\"].shift(1)) | (mon_df[\"Day\"] == mon_df[\"Day\"].shift(-1))]\n",
    "\n",
    "    ###### converting to central time. also handles daylight savings time inconsistencies\n",
    "    # times of raw data appear to be utc\n",
    "    mon_df[\"UTC_Time\"] = mon_df.index.tz_localize(\"UTC\")\n",
    "    mon_df.set_index(\"UTC_Time\", inplace=True)\n",
    "\n",
    "    mon_df[\"Central_Time\"] = mon_df.index.tz_convert(\"US/Central\")\n",
    "    mon_df.set_index(\"Central_Time\", inplace=True)\n",
    "\n",
    "    mon_df[\"Time\"] = mon_df.index.time\n",
    "    \n",
    "    ###### want to get open price (first price of minute 8:30) while still being able to get the last price of minute 8:30\n",
    "    \n",
    "    # if no trading in the first minute, that's fine because we're calculating intraday volatility and the first however\n",
    "    # many minutes will be all the same value padded from the previous close/overnight trading. Also, don't want to make\n",
    "    # a later price the open price before it's actually traded\n",
    "\n",
    "    # getting all the open prices separately and making their times 8:29\n",
    "    open_df = mon_df.loc[(mon_df[\"Time\"] >= dt.time(hour=8, minute=30, second=0)) & (mon_df[\"Time\"] < dt.time(hour=8, minute=31, second=0))]\n",
    "\n",
    "    # drop rows if the previous row is from the same day\n",
    "    open_df = open_df.loc[open_df[\"Day\"] != open_df[\"Day\"].shift(1)]\n",
    "\n",
    "    open_df.index = open_df.index.shift(periods=-1, freq=\"T\")\n",
    "\n",
    "    # getting rid of any other times that are 8:29 to make way for the open prices - resampling by last value of minute later\n",
    "    mon_df = mon_df.loc[(mon_df[\"Time\"] < dt.time(hour=8, minute=29, second=0)) | (mon_df[\"Time\"] > dt.time(hour=8, minute=29, second=59))]\n",
    "\n",
    "    # concatenating dataframes and putting back in the right order\n",
    "    mon_df = pd.concat([mon_df, open_df], sort=False).sort_index()\n",
    "    mon_df[\"Time\"] = mon_df.index.time # make open times 8:29 instead of 8:30\n",
    "    \n",
    "    ###### convert to minute frequency, taking the last value within each minute - gets open price (8:29) & close price (13:04)\n",
    "    mon_df = mon_df.resample(\"1T\").last()\n",
    "    \n",
    "    # go to next iteration if there's no second-frequency data for the time period the contract is traded in\n",
    "    if len(mon_df) == 0:\n",
    "        continue\n",
    "    \n",
    "    ###### it looks like we need to remove non-market days & times because resample basically picked every minute from \n",
    "    # the start to the end of the data which is nice in some ways but not nice in others\n",
    "    \n",
    "    mon_df[\"Day\"] = mon_df.index.date\n",
    "    mon_df[\"Time\"] = mon_df.index.time # going to need this later to get only market hours\n",
    "\n",
    "    # resetting the index so .loc works with a datetime index and doesnt end up turning the data to daily frequency\n",
    "    mon_df.reset_index(inplace=True) # want to keep old index as column\n",
    "    mon_df.set_index(\"Day\", inplace=True)\n",
    "    \n",
    "    mon_df.index = pd.to_datetime(mon_df.index)\n",
    "    \n",
    "    # taking only business days according to our cme calendar\n",
    "    bus_days = pd.date_range(start=mon_df.index[0], end=mon_df.index[-1], freq=cme_cal).sort_values(ascending=True)\n",
    "    mon_df = mon_df.loc[bus_days]\n",
    "    \n",
    "    # now trying to just get market hours, which are 8:30 to 13:05 just looking at the data\n",
    "    mon_df.reset_index(inplace=True)\n",
    "    mon_df.set_index(\"Time\", drop=False, inplace=True)\n",
    "    mon_df = mon_df.loc[(mon_df.index >= dt.time(hour=8, minute=29, second=0)) & (mon_df.index <= dt.time(hour=13, minute=4, second=0))]\n",
    "    \n",
    "    # took open price (8:29) through close price (last price of 13:04) so now we adjust the index to make it 8:30-13:05\n",
    "    mon_df.set_index(\"Central_Time\", inplace=True)\n",
    "    mon_df.index = mon_df.index.shift(periods=1, freq=\"T\")\n",
    "    mon_df[\"Time\"] = mon_df.index.time # have to reset time again...\n",
    "    \n",
    "    ###### now we want to fill in missing values, probably by using the most recent price. so this is \"padding\" i think\n",
    "    mon_df.interpolate(method=\"pad\", inplace=True)\n",
    "    \n",
    "    ###### dropping first day of every contract in case trading doesn't start exactly at the open (13:30) since it wouldn't have gotten interpolated\n",
    "    mon_df = mon_df.loc[mon_df[\"Day\"] != mon_df.loc[mon_df.index[0], \"Day\"]]\n",
    "    \n",
    "    # check that there aren't any empty dataframes\n",
    "    if len(mon_df) == 0:\n",
    "        continue\n",
    "    \n",
    "    contract_vol_dict[month] = mon_df\n",
    "    \n",
    "    print(month)\n",
    "    \n",
    "contract_vol_dict[\"JUL18\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-english",
   "metadata": {},
   "source": [
    "List of contracts above is the list of contracts where some minute data exists. A lot of times it's just one random day where prices for two different times are listed instead of one, but that means the whole dataframe gets kept and interpolated. With actual data it will make more sense.\n",
    "\n",
    "Now that the data is nicely formatted, we need to get daily volatility data for each day. Since we ultimately want to end up with daily frequency dataframes for each contract, we might as well create those now and just put the daily volatility data directly in there. \n",
    "\n",
    "We're still going to need to do everything for each contract, so we'll have to iterate through the dictionary we created in the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "consecutive-begin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Price</th>\n",
       "      <th>Daily_Vol</th>\n",
       "      <th>Annualized_Vol</th>\n",
       "      <th>Vol_2</th>\n",
       "      <th>Abs_Change_2</th>\n",
       "      <th>Change_2</th>\n",
       "      <th>Vol_5</th>\n",
       "      <th>Abs_Change_5</th>\n",
       "      <th>Change_5</th>\n",
       "      <th>Vol_10</th>\n",
       "      <th>Abs_Change_10</th>\n",
       "      <th>Change_10</th>\n",
       "      <th>Vol_20</th>\n",
       "      <th>Abs_Change_20</th>\n",
       "      <th>Change_20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>82.725</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.150941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>81.300</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.151288</td>\n",
       "      <td>0.151114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>80.300</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.174192</td>\n",
       "      <td>0.162740</td>\n",
       "      <td>2.425</td>\n",
       "      <td>-2.425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>80.375</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.138734</td>\n",
       "      <td>0.156463</td>\n",
       "      <td>0.925</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-09</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>80.125</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.111533</td>\n",
       "      <td>0.125134</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.145338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>54.975</td>\n",
       "      <td>0.017425</td>\n",
       "      <td>0.276606</td>\n",
       "      <td>0.243181</td>\n",
       "      <td>1.450</td>\n",
       "      <td>-1.450</td>\n",
       "      <td>0.215776</td>\n",
       "      <td>5.150</td>\n",
       "      <td>-5.150</td>\n",
       "      <td>0.206240</td>\n",
       "      <td>11.250</td>\n",
       "      <td>-11.250</td>\n",
       "      <td>0.199939</td>\n",
       "      <td>13.700</td>\n",
       "      <td>-13.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-09</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>55.100</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.244863</td>\n",
       "      <td>0.260734</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-0.675</td>\n",
       "      <td>0.231658</td>\n",
       "      <td>3.650</td>\n",
       "      <td>-3.650</td>\n",
       "      <td>0.207289</td>\n",
       "      <td>9.950</td>\n",
       "      <td>-9.950</td>\n",
       "      <td>0.200374</td>\n",
       "      <td>15.225</td>\n",
       "      <td>-15.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>54.875</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.188701</td>\n",
       "      <td>0.216782</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.230032</td>\n",
       "      <td>3.475</td>\n",
       "      <td>-3.475</td>\n",
       "      <td>0.208883</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>0.200526</td>\n",
       "      <td>15.325</td>\n",
       "      <td>-15.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-13</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>55.525</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.124269</td>\n",
       "      <td>0.156485</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.208839</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>0.206416</td>\n",
       "      <td>7.700</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>0.195495</td>\n",
       "      <td>13.775</td>\n",
       "      <td>-13.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-14</th>\n",
       "      <td>HE</td>\n",
       "      <td>AUG18</td>\n",
       "      <td>55.050</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.088939</td>\n",
       "      <td>0.106604</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.184675</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>0.195250</td>\n",
       "      <td>6.125</td>\n",
       "      <td>-6.125</td>\n",
       "      <td>0.191724</td>\n",
       "      <td>12.975</td>\n",
       "      <td>-12.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Product Contract   Price  Daily_Vol  Annualized_Vol     Vol_2  \\\n",
       "Date                                                                       \n",
       "2018-02-05      HE    AUG18  82.725   0.009508        0.150941       NaN   \n",
       "2018-02-06      HE    AUG18  81.300   0.009530        0.151288  0.151114   \n",
       "2018-02-07      HE    AUG18  80.300   0.010973        0.174192  0.162740   \n",
       "2018-02-08      HE    AUG18  80.375   0.008739        0.138734  0.156463   \n",
       "2018-02-09      HE    AUG18  80.125   0.007026        0.111533  0.125134   \n",
       "...            ...      ...     ...        ...             ...       ...   \n",
       "2018-08-08      HE    AUG18  54.975   0.017425        0.276606  0.243181   \n",
       "2018-08-09      HE    AUG18  55.100   0.015425        0.244863  0.260734   \n",
       "2018-08-10      HE    AUG18  54.875   0.011887        0.188701  0.216782   \n",
       "2018-08-13      HE    AUG18  55.525   0.007828        0.124269  0.156485   \n",
       "2018-08-14      HE    AUG18  55.050   0.005603        0.088939  0.106604   \n",
       "\n",
       "            Abs_Change_2  Change_2     Vol_5  Abs_Change_5  Change_5  \\\n",
       "Date                                                                   \n",
       "2018-02-05           NaN       NaN       NaN           NaN       NaN   \n",
       "2018-02-06           NaN       NaN       NaN           NaN       NaN   \n",
       "2018-02-07         2.425    -2.425       NaN           NaN       NaN   \n",
       "2018-02-08         0.925    -0.925       NaN           NaN       NaN   \n",
       "2018-02-09         0.175    -0.175  0.145338           NaN       NaN   \n",
       "...                  ...       ...       ...           ...       ...   \n",
       "2018-08-08         1.450    -1.450  0.215776         5.150    -5.150   \n",
       "2018-08-09         0.675    -0.675  0.231658         3.650    -3.650   \n",
       "2018-08-10         0.100    -0.100  0.230032         3.475    -3.475   \n",
       "2018-08-13         0.425     0.425  0.208839         0.900    -0.900   \n",
       "2018-08-14         0.175     0.175  0.184675         0.725    -0.725   \n",
       "\n",
       "              Vol_10  Abs_Change_10  Change_10    Vol_20  Abs_Change_20  \\\n",
       "Date                                                                      \n",
       "2018-02-05       NaN            NaN        NaN       NaN            NaN   \n",
       "2018-02-06       NaN            NaN        NaN       NaN            NaN   \n",
       "2018-02-07       NaN            NaN        NaN       NaN            NaN   \n",
       "2018-02-08       NaN            NaN        NaN       NaN            NaN   \n",
       "2018-02-09       NaN            NaN        NaN       NaN            NaN   \n",
       "...              ...            ...        ...       ...            ...   \n",
       "2018-08-08  0.206240         11.250    -11.250  0.199939         13.700   \n",
       "2018-08-09  0.207289          9.950     -9.950  0.200374         15.225   \n",
       "2018-08-10  0.208883          8.800     -8.800  0.200526         15.325   \n",
       "2018-08-13  0.206416          7.700     -7.700  0.195495         13.775   \n",
       "2018-08-14  0.195250          6.125     -6.125  0.191724         12.975   \n",
       "\n",
       "            Change_20  \n",
       "Date                   \n",
       "2018-02-05        NaN  \n",
       "2018-02-06        NaN  \n",
       "2018-02-07        NaN  \n",
       "2018-02-08        NaN  \n",
       "2018-02-09        NaN  \n",
       "...               ...  \n",
       "2018-08-08    -13.700  \n",
       "2018-08-09    -15.225  \n",
       "2018-08-10    -15.325  \n",
       "2018-08-13    -13.775  \n",
       "2018-08-14    -12.975  \n",
       "\n",
       "[133 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dictionary for the daily dataframes. This is starting to get messy\n",
    "\n",
    "daily_contract_dict = {}\n",
    "\n",
    "for contract in contract_vol_dict.keys():\n",
    "    min_df = contract_vol_dict[contract].copy()\n",
    "    \n",
    "    # new daily frequency dataframe\n",
    "    day_df = min_df.resample(\"1D\").last()\n",
    "    \n",
    "    #### and we have to remove non business days. again\n",
    "    \n",
    "    day_df[\"Day\"] = day_df.index.date\n",
    "    day_df.reset_index(inplace=True)\n",
    "    day_df.set_index(\"Day\", inplace=True)\n",
    "    \n",
    "    day_df.index = pd.to_datetime(day_df.index)\n",
    "    \n",
    "    # taking only business days according to our cme calendar\n",
    "    bus_days = pd.date_range(start=day_df.index[0], end=day_df.index[-1], freq=cme_cal).sort_values(ascending=True)\n",
    "    day_df = day_df.loc[bus_days]\n",
    "    \n",
    "\n",
    "    #### now we can get started getting daily vol\n",
    "    day_df.set_index(\"Central_Time\", inplace=True)\n",
    "    day_df[\"Date\"] = day_df.index.date\n",
    "    \n",
    "    # another long line... calculates standard deviation of minute log returns and then scales by number of minutes in trading day (number of prices - 1)\n",
    "    # calculates intraday vol: doesn't include any changes from close to open\n",
    "    day_df[\"Daily_Vol\"] = day_df[\"Date\"].apply(lambda x: abs(np.log(min_df.loc[min_df[\"Day\"] == str(x)][\"Price\"]) - np.log(min_df.loc[min_df[\"Day\"] == str(x)][\"Price\"].shift(1))).dropna().std()*np.sqrt(len(min_df.loc[min_df[\"Day\"] == str(x)])-1))\n",
    "    \n",
    "    day_df[\"Annualized_Vol\"] = day_df[\"Daily_Vol\"]*np.sqrt(252)\n",
    "    \n",
    "    for t in [2, 5, 10, 20]:\n",
    "        day_df[f\"Vol_{t}\"] = day_df[\"Annualized_Vol\"].rolling(t).mean()\n",
    "        day_df[f\"Abs_Change_{t}\"] = abs(day_df[\"Price\"] - day_df[\"Price\"].shift(t))\n",
    "        day_df[f\"Change_{t}\"] = day_df[\"Price\"] - day_df[\"Price\"].shift(t)\n",
    "    \n",
    "    # set the index to be just the day. Makes things easier when we read in to do analysis and we aren't really losing any info\n",
    "    day_df.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    day_df.drop(columns=[\"Index\", \"???\", \"Time\"], inplace=True)\n",
    "    \n",
    "#     print(day_df)\n",
    "    \n",
    "    daily_contract_dict[contract] = day_df\n",
    "    \n",
    "    # exporting to csv so we can use it for regressions in the hog_analysis notebook\n",
    "    day_df.to_csv(f\"../data/{contract}.csv\")\n",
    "    \n",
    "daily_contract_dict[\"AUG18\"]    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-titanium",
   "metadata": {},
   "source": [
    "The rest of the cells are just me trying stuff out to get to the results above, primarily for the first for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "prepared-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the july 2019 dataframe just to try stuff on\n",
    "jul_df = contract_vol_dict[\"JUL19\"].copy()\n",
    "\n",
    "# this didn't actually work so much because we didn't get the open price\n",
    "\n",
    "jul_df = jul_df.resample(\"1T\").last\n",
    "\n",
    "jul_df[\"Day\"] = jul_df.index.date\n",
    "jul_df[\"Time\"] = jul_df.index.time # going to need this later to get only market hours\n",
    "\n",
    "# it looks like we need to remove non-market days & times because resample basically included every minute from \n",
    "# the start to the end of the data which is nice in some ways but not nice in others\n",
    "\n",
    "# resetting the index so .loc works with a datetime index and doesnt end up turning the data to daily frequency\n",
    "jul_df.reset_index(inplace=True) # want to keep old index as column\n",
    "jul_df.set_index(\"Day\", drop=False, inplace=True)\n",
    "\n",
    "# print(jul_df)\n",
    "\n",
    "jul_df.index = pd.to_datetime(jul_df.index)\n",
    "\n",
    "# print(jul_df)\n",
    "\n",
    "bus_days = pd.date_range(start=jul_df.index[0], end=jul_df.index[-1], freq=cme_cal).sort_values(ascending=False)\n",
    "# print(bus_days)\n",
    "\n",
    "jul_df = jul_df.loc[bus_days]\n",
    "\n",
    "# print(jul_df)\n",
    "\n",
    "print(jul_df[\"Price\"].isna().sum())\n",
    "\n",
    "jul_df.set_index(\"Time\", drop=False, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "jul_df.to_csv(\"../data/jul_19_vol.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "growing-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the july 2019 dataframe just to try stuff on\n",
    "jul_df = contract_vol_dict[\"JUL19\"].copy()\n",
    "\n",
    "# want to get open price (first price of minute 8:30 while still being able to get the last price of minute 8:30)\n",
    "# if no trading in the first minute, that's fine because we're calculating intraday volatility and the first however\n",
    "# many minutes will be all the same value padded from the previous close/overnight trading. Also, don't want to make\n",
    "# a later price the open price before it's actually traded\n",
    "\n",
    "# getting all the open prices separately and making their times 8:29\n",
    "open_df = jul_df.loc[(jul_df[\"Time\"] >= dt.time(hour=8, minute=30, second=0)) & (jul_df[\"Time\"] < dt.time(hour=8, minute=31, second=0))]\n",
    "\n",
    "# drop rows if the previous row is from the same day\n",
    "open_df = open_df.loc[open_df[\"Day\"] != open_df[\"Day\"].shift(1)]\n",
    "\n",
    "open_df.index = open_df.index.shift(periods=-1, freq=\"T\")\n",
    "\n",
    "# getting rid of any other times that are 8:29 to make way for the open prices\n",
    "jul_df = jul_df.loc[(jul_df[\"Time\"] < dt.time(hour=8, minute=29, second=0)) | (jul_df[\"Time\"] > dt.time(hour=8, minute=29, second=59))]\n",
    "\n",
    "# concatenating dataframes and putting back in the right order\n",
    "jul_df = pd.concat([jul_df, open_df], sort=False).sort_index()\n",
    "jul_df[\"Time\"] = jul_df.index.time\n",
    "\n",
    "jul_df\n",
    "\n",
    "jul_df.to_csv(\"../data/jul_19_vol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now trying to just get market hours\n",
    "jul_df = jul_df.loc[(jul_df.index >= dt.time(hour=13, minute=30, second=0)) & (jul_df.index <= dt.time(hour=18, minute=5, second=0))]\n",
    "\n",
    "\n",
    "print(jul_df)\n",
    "\n",
    "jul_df.to_csv(\"../data/jul_19_vol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to fill in missing values, probably by using the most recent price. so this is \"padding\" i think\n",
    "jul_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "jul_df.interpolate(method=\"pad\", inplace=True)\n",
    "\n",
    "jul_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compound-burlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Central_Time</th>\n",
       "      <th>Index</th>\n",
       "      <th>Product</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Price</th>\n",
       "      <th>???</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>08:53:00</th>\n",
       "      <td>2018-08-01 08:53:00-05:00</td>\n",
       "      <td>4404676.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL19</td>\n",
       "      <td>71.775</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>08:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08:54:00</th>\n",
       "      <td>2018-08-01 08:54:00-05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>08:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08:55:00</th>\n",
       "      <td>2018-08-01 08:55:00-05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>08:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08:56:00</th>\n",
       "      <td>2018-08-01 08:56:00-05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>08:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08:57:00</th>\n",
       "      <td>2018-08-01 08:57:00-05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>08:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:48:00</th>\n",
       "      <td>2018-11-16 13:48:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>13:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:49:00</th>\n",
       "      <td>2018-11-16 13:49:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>13:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:50:00</th>\n",
       "      <td>2018-11-16 13:50:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>13:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:51:00</th>\n",
       "      <td>2018-11-16 13:51:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>13:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:52:00</th>\n",
       "      <td>2018-11-16 13:52:00-06:00</td>\n",
       "      <td>5913805.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL19</td>\n",
       "      <td>84.825</td>\n",
       "      <td>84.0250000000</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>13:52:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109800 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Central_Time      Index Product Contract   Price  \\\n",
       "Time                                                                     \n",
       "08:53:00 2018-08-01 08:53:00-05:00  4404676.0      HE    JUL19  71.775   \n",
       "08:54:00 2018-08-01 08:54:00-05:00        NaN    None     None     NaN   \n",
       "08:55:00 2018-08-01 08:55:00-05:00        NaN    None     None     NaN   \n",
       "08:56:00 2018-08-01 08:56:00-05:00        NaN    None     None     NaN   \n",
       "08:57:00 2018-08-01 08:57:00-05:00        NaN    None     None     NaN   \n",
       "...                            ...        ...     ...      ...     ...   \n",
       "13:48:00 2018-11-16 13:48:00-06:00        NaN    None     None     NaN   \n",
       "13:49:00 2018-11-16 13:49:00-06:00        NaN    None     None     NaN   \n",
       "13:50:00 2018-11-16 13:50:00-06:00        NaN    None     None     NaN   \n",
       "13:51:00 2018-11-16 13:51:00-06:00        NaN    None     None     NaN   \n",
       "13:52:00 2018-11-16 13:52:00-06:00  5913805.0      HE    JUL19  84.825   \n",
       "\n",
       "                    ???         Day      Time  \n",
       "Time                                           \n",
       "08:53:00             \\N  2018-08-01  08:53:00  \n",
       "08:54:00           None  2018-08-01  08:54:00  \n",
       "08:55:00           None  2018-08-01  08:55:00  \n",
       "08:56:00           None  2018-08-01  08:56:00  \n",
       "08:57:00           None  2018-08-01  08:57:00  \n",
       "...                 ...         ...       ...  \n",
       "13:48:00           None  2018-11-16  13:48:00  \n",
       "13:49:00           None  2018-11-16  13:49:00  \n",
       "13:50:00           None  2018-11-16  13:50:00  \n",
       "13:51:00           None  2018-11-16  13:51:00  \n",
       "13:52:00  84.0250000000  2018-11-16  13:52:00  \n",
       "\n",
       "[109800 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to fix timezone stuff :(\n",
    "\n",
    "jul_df = contract_vol_dict[\"JUL19\"].copy()\n",
    "jul_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "jul_df[\"UTC_Time\"] = jul_df.index.tz_localize(\"UTC\")\n",
    "\n",
    "jul_df.set_index(\"UTC_Time\", inplace=True)\n",
    "\n",
    "jul_df[\"Central_Time\"] = jul_df.index.tz_convert(\"US/Central\")\n",
    "jul_df.set_index(\"Central_Time\", inplace=True)\n",
    "\n",
    "jul_df[\"Time\"] = jul_df.index.time\n",
    "\n",
    "jul_df.reset_index(inplace=True)\n",
    "jul_df.set_index(\"Time\", drop=False, inplace=True)\n",
    "\n",
    "jul_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exempt-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "jul_df.to_csv(\"../data/jul_tz_vol.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-intake",
   "metadata": {},
   "source": [
    "The next thing is to turn this into volatility data, so the main tasks i see are to figure out how many minutes are in a typical day for this data, then get minute-by-minute log returns, then get daily volatility, then convert to annual volatility (should be multiplying by sqrt(# periods in day) * sqrt(252)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_df = contract_vol_dict[\"OCT18\"].copy()\n",
    "\n",
    "# i think we should drop the first day of all the dataframes because they don't start trading at 13:30 for some reason? \n",
    "# Shouldn't matter for our purposes anyway\n",
    "# going to make the change in the main loop at the top of this notebook\n",
    "\n",
    "# oct_df.loc[oct_df.index[0], \"Day\"]\n",
    "\n",
    "#oct_df.loc[oct_df[\"Day\"] != oct_df.loc[oct_df.index[0], \"Day\"]]\n",
    "\n",
    "# going to need to figure out how to take vol of the last day... trading seems to stop an hour before close?\n",
    "# maybe need to handle as a special case. shouldn't be too hard hopefully\n",
    "\n",
    "# how many mins in a day\n",
    "len(oct_df.loc[oct_df[\"Day\"] == oct_df.loc[oct_df.index[800], \"Day\"]])\n",
    "# looks like 276\n",
    "# what about the last day\n",
    "len(oct_df.loc[oct_df[\"Day\"] == oct_df.loc[oct_df.index[-1], \"Day\"]])\n",
    "# only 210..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-tourist",
   "metadata": {},
   "source": [
    "Now i'm pretty much ready to take log returns of all this, but I'm wondering if the log returns should capture interday volatility. I imagine they should since they would be pretty inaccurate otherwise. So I'm going to pretty much just take log returns and not worry too much about divisions between dates. First I think I'm going to reverse the order of the dataframe to keep it consistent with the bloomberg output. Easy to undo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oct_df = oct_df[::-1]\n",
    "\n",
    "oct_df[\"Abs_Minute_Log_Return\"] = abs(np.log(oct_df[\"Price\"]) - np.log(oct_df[\"Price\"].shift(-1)))*100\n",
    "\n",
    "oct_df\n",
    "\n",
    "# check out the mean of non abs log returns out of curiosity\n",
    "oct_df[\"Minute_Log_Return\"] = np.log(oct_df[\"Price\"]) - np.log(oct_df[\"Price\"].shift(-1))\n",
    "oct_df[\"Minute_Log_Return\"].mean()\n",
    "# its like -4.624e-7 so pretty much 0. cool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-picnic",
   "metadata": {},
   "source": [
    "Since we want volatility for periods of days, I'm realizing that it's probably not the best idea to get daily volatility first. So, what I'm going to try to do next is just find two day volatility for the last two days of this data and see how that goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to figure out rolling window size. \n",
    "\n",
    "# set number of days\n",
    "for t in [2, 5, 10, 20]:\n",
    "    # now get winsize - 276 mins in a day except for the last and the first day\n",
    "    # Probably don't need to worry about first day since volatility on that day is likely very close to 0 anyway\n",
    "    # then just add the number of \n",
    "    winsize = t*276\n",
    "    # formula we want to use\n",
    "    oct_df[f\"Vol_{t}\"] = oct_df[\"Abs_Minute_Log_Return\"].rolling(winsize).std().shift(1-winsize)*np.sqrt(276*252)\n",
    "    # now handle last day as special case\n",
    "    winsize = (t-1)*276 + len(oct_df.loc[oct_df[\"Day\"] == oct_df.loc[oct_df.index[-1], \"Day\"]])\n",
    "    # uh how am i going to annualize this if there are fewer periods on the last day...currently using average mins per day over period\n",
    "    oct_df.loc[oct_df.index[0], f\"Vol_{t}\"] = oct_df.loc[oct_df.index[0]:oct_df.index[winsize-1], \"Abs_Minute_Log_Return\"].std()*np.sqrt((winsize/t)*252)\n",
    "\n",
    "    # uhh just realized to get the actual accurate volatility for each minute of the last day we'd need to keep \n",
    "    # increasing the window size by 1 each minute to keep capturing all of the second to last day. yikes\n",
    "\n",
    "oct_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_vol_df.set_index(\"Date\", inplace=True)\n",
    "hog_vol_df.index = pd.to_datetime(hog_vol_df.index)\n",
    "\n",
    "date_slice = hog_vol_df.loc[hog_vol_df.index > \"2018-10-01\"]\n",
    "date_slice.to_csv(\"../data/vol_date_slice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_slice = hog_vol_df.loc[hog_vol_df.index > \"2018-10-01\"]\n",
    "date_slice.to_csv(\"../data/vol_date_slice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_vol_dict[\"JUL19\"].to_csv(\"../data/july_vol_slice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_vol_dict[\"FEB21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "balanced-algeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Index</th>\n",
       "      <th>Product</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Price</th>\n",
       "      <th>???</th>\n",
       "      <th>Time</th>\n",
       "      <th>Abs_Minute_Log_Return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-16 12:00:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163498.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.750</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>0.031353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 11:59:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163452.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 11:58:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163314.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11:58:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 11:57:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163314.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11:57:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16 11:56:00-05:00</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>4163314.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.725</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11:56:00</td>\n",
       "      <td>0.062696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-13 12:31:00-05:00</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>4143635.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.975</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12:31:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-13 12:30:00-05:00</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>4143635.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.975</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-13 12:29:00-05:00</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>4143603.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.975</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12:29:00</td>\n",
       "      <td>0.031265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-13 12:28:00-05:00</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>4143252.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.950</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12:28:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-13 12:27:00-05:00</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>4143252.0</td>\n",
       "      <td>HE</td>\n",
       "      <td>JUL18</td>\n",
       "      <td>79.950</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12:27:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Day      Index Product Contract   Price ???  \\\n",
       "Central_Time                                                                   \n",
       "2018-07-16 12:00:00-05:00 2018-07-16  4163498.0      HE    JUL18  79.750  \\N   \n",
       "2018-07-16 11:59:00-05:00 2018-07-16  4163452.0      HE    JUL18  79.725  \\N   \n",
       "2018-07-16 11:58:00-05:00 2018-07-16  4163314.0      HE    JUL18  79.725  \\N   \n",
       "2018-07-16 11:57:00-05:00 2018-07-16  4163314.0      HE    JUL18  79.725  \\N   \n",
       "2018-07-16 11:56:00-05:00 2018-07-16  4163314.0      HE    JUL18  79.725  \\N   \n",
       "...                              ...        ...     ...      ...     ...  ..   \n",
       "2018-07-13 12:31:00-05:00 2018-07-13  4143635.0      HE    JUL18  79.975  \\N   \n",
       "2018-07-13 12:30:00-05:00 2018-07-13  4143635.0      HE    JUL18  79.975  \\N   \n",
       "2018-07-13 12:29:00-05:00 2018-07-13  4143603.0      HE    JUL18  79.975  \\N   \n",
       "2018-07-13 12:28:00-05:00 2018-07-13  4143252.0      HE    JUL18  79.950  \\N   \n",
       "2018-07-13 12:27:00-05:00 2018-07-13  4143252.0      HE    JUL18  79.950  \\N   \n",
       "\n",
       "                               Time  Abs_Minute_Log_Return  \n",
       "Central_Time                                                \n",
       "2018-07-16 12:00:00-05:00  12:00:00               0.031353  \n",
       "2018-07-16 11:59:00-05:00  11:59:00               0.000000  \n",
       "2018-07-16 11:58:00-05:00  11:58:00               0.000000  \n",
       "2018-07-16 11:57:00-05:00  11:57:00               0.000000  \n",
       "2018-07-16 11:56:00-05:00  11:56:00               0.062696  \n",
       "...                             ...                    ...  \n",
       "2018-07-13 12:31:00-05:00  12:31:00               0.000000  \n",
       "2018-07-13 12:30:00-05:00  12:30:00               0.000000  \n",
       "2018-07-13 12:29:00-05:00  12:29:00               0.031265  \n",
       "2018-07-13 12:28:00-05:00  12:28:00               0.000000  \n",
       "2018-07-13 12:27:00-05:00  12:27:00               0.000000  \n",
       "\n",
       "[250 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract_vol_dict[\"JUL18\"].head(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-publication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
